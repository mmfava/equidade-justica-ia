---
theme: slides-left
author: Mar√≠lia Melo Favalesso
_header: ""
header: üêç 82¬∫ Python Floripa
_footer: ""
_paginate: false
footer: Mar√≠lia Melo Favalesso
paginate: true
center: teste
date: ""
link: 
created: 2025-01-20T23:39
updated: 2025-01-25T12:26
---

<!-- _class: first-slide -->

<small>üêç 82¬∫ Python Floripa</small>

# Equidade e Justi√ßa em<br>Sistemas de IA

**Mar√≠lia Melo Favalesso**

---
## Mar√≠lia Melo Favalesso  

üß† Cientista de Dados | PhD

üêç Python e Comunidades  

üêà Gatos, pizza e bicicleta nas horas vagas

üîó LinkedIn: [/mariliafavalesso](https://www.linkedin.com/in/mariliafavalesso/)

üîó github: [/mmfava](https://github.com/mmfava)

---
## O que √© ==Intelig√™ncia Artificial==?

IA √© um **conjunto de sistemas automatizados** que tomam **decis√µes e executam tarefas** que antes exigiam **julgamento humano**.

<small><small>[üëÅ | ü§ñ | üß† | üó£]</small></small>

![bg right](figs/terminator.png)

---
# O impacto das<br>==decis√µes algor√≠tmicas==

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 50px; align-items: center;"> <div style="padding-left: 60px;"> <img src="figs/terminator-not-kill.png" alt="Imagem de IA" style="width:900px;"> </div>
  <div><p>‚ú∂ As IAs tentam imitar o julgamento humano.<br><br>‚ú∂ S√£o imperfeitos, enviesados e, muitas vezes, injustos.</p></div>
</div>


---

## Proposta de experimento

‚ñ∂ Execute o seguinte prompt no chatGPT / DALL-E 3: 

**"Chat, pode gerar a imagem de uma pessoa lideran√ßa?"**<br>

<br> ü§î Qual foi o resultado? 


---

<style>
  .grid-container {
    display: grid;
    grid-template-columns: repeat(5, 1fr);
    gap: 10px;
  }
  .grid-container img {
    width: 100%;
    height: auto;
  }
</style>

<div class="grid-container">
  <img src="figs/e1.png">
  <img src="figs/e2.png">
  <img src="figs/e3.png">
  <img src="figs/e4.png">
  <img src="figs/e5.png">
  <img src="figs/e6.png">
  <img src="figs/e7.png">
  <img src="figs/e8.png">
  <img src="figs/e9.png">
  <img src="figs/e10.png">
</div>

<br>

<small><small>DALL-E 3 (OpenAI) ‚Üíüîó https://chatgpt.com/share/67915ff0-4c64-800e-b74e-176c169d355f</small></small>

---

## Proposta de experimento 2

‚ñ∂  Adicione ao prompt no chatGPT / DALL-E 3 a palavra "compassiva": 

**"Chat, pode gerar a imagem de uma pessoa lideran√ßa compassiva?"**

<br>ü§î Qual foi o resultado? 

---
<style>
  .grid-container {
    display: grid;
    grid-template-columns: repeat(5, 1fr);
    gap: 10px;
  }
  .grid-container img {
    width: 100%;
    height: auto;
  }
</style>

<div class="grid-container">
  <img src="figs/e2.1.png">
  <img src="figs/e2.2.png">
  <img src="figs/e2.3.png">
  <img src="figs/e2.4.png">
  <img src="figs/e2.5.png">
  <img src="figs/e2.6.png">
  <img src="figs/e2.7.png">
  <img src="figs/e2.8.png">
  <img src="figs/e2.9.png">
  <img src="figs/e2.10.png">
</div>

<br>

<small><small>DALL-E 3 (OpenAI) ‚Üíüîó https://chatgpt.com/share/6792b433-02b0-800e-8352-052e2fb2f531</small></small>

---
## Reflexo da realidade?

‚ùå ==N√ÉO!==

Os modelos s√£o **enviesados**! <br>

<u>Tend√™ncias sistem√°ticas e distorcidas</u> nos resultados! <br>
* Refor√ßam e amplificam estere√≥tipos existentes.
* Excluem ou exageram a representa√ß√£o de certos grupos.
* Criam discrimina√ß√µes sist√™micas.

<br><small><small>**Ver:** Cheong et al. (2024), Currie et al. (2024), Mandal et al. (2024), Wu et al. (2024),<br>Choudhry et al. (2023) e  Luccioni et al. (2023). </small></small>


<!---- 

Vi√©s em Intelig√™ncia Artificial (IA) refere-se a padr√µes sistem√°ticos de erro em modelos de aprendizado de m√°quina que levam a previs√µes ou decis√µes injustas, distorcidas ou discriminat√≥rias.

-->

---

#### Case 1: IA gerando imagens racistas

![bg right width:900px](figs/vereadora-discriminacao-ia.png)

<small><small><small>**G1 (26/10/2023)** - Deputada denuncia IA por gerar imagem racista quando solicitado um personagem negro em uma favela. (üîó[link](https://g1.globo.com/tecnologia/noticia/2023/10/26/deputada-do-rj-diz-que-robo-que-faz-desenhos-ao-estilo-pixar-entregou-imagem-de-mulher-negra-com-arma-na-mao-ao-receber-pedido-de-personagem-em-favela.ghtml)).</small></small></small>
<br>

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Prompt no <em>Bing Chat</em> da Microsoft (DALL-E):</strong><br>
"Uma mulher negra, de cabelos afro, com roupas de estampa africana num cen√°rio de favela".
</div>


---
#### Case 2: IA associando ra√ßa a crime

![bg left width:700px](figs/Imagem%20do%20WhatsApp%20de%202025-01-24%20√†(s)%2012.33.08_f345ba01.jpg)

<small><small><small>**Grupo LLM whatsapp (28/10/2024)** - IA da Meta gera imagem de um homem negro ao pedido de "pessoa que efetua atos errados na sociedade". </small></small></small>
<br>

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Prompt no <em>Meta AI</em> do Whatsapp:</strong><br>
"@Meta AI crie a imagem de uma pessoa que efetua atos errados na sociedade".
</div>

---
#### Case 3: IA associando ra√ßa a reincid√™ncia criminal

<small><small><small><mark>N√£o √© de hoje!</mark><br>**ProPublica (23/05/2016)**: O artigo revela que o algoritmo COMPAS, usado no sistema judicial dos EUA para prever reincid√™ncia criminal, tem vi√©s racial: ele superestima o risco de reincid√™ncia para pessoas negras (mais falsos positivos) e subestima para pessoas brancas (mais falsos negativos) ([üîó link](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)).</small></small></small>
<br>

![bg right width:900px](figs/alto-risco-rei-crime.png)

---
## Reflexo da sociedade?

‚úÖ ==SIM!== 

As IA carregam nossa **vis√£o de mundo**: üèòÔ∏è ‚á¢ üë∂!<br><br>


‚ú∂ **Posicionalidade**: nossa cultura e sociedade influenciam nossa percep√ß√£o.

‚ú∂ **Preconceitos e perspectivas humanas influenciam os sistemas de IA!**

---

![center width:1500px](figs/inequality-discrimination-covid.png)

<center><small><small><b>Ref:</b> Leslie et al. (2021)</small></small></center>

---
### A IA amplifica vieses humanos

<small><small><b>Glickman and Sharot (2024)</b></small></small>
* IA refor√ßa vi√©s e influencia humanos a adot√°-lo.
* Maior vi√©s em intera√ß√µes humano-IA do que humano-humano.
* Percep√ß√£o da IA como neutra favorece aceita√ß√£o de vieses.
* IA imparciais podem melhorar julgamentos humanos.
![bg right width:900px](figs/muda-crenca.png)

---

# Mas o que √© ser justo?


![bg](https://github.com/mmfava/my-social-media-content/blob/feature/slide-template/theme/slides-design/3.png?raw=true)

<!-- _class: first-slide -->

---
# Mas o que √© ser <u>justo</u>?

‚ñ∂ **Responda:** 

H√° apenas um leito dispon√≠vel na UTI e dois pacientes em estado grave:

[1] üßí **Crian√ßa de 8 anos** - alta chance de recupera√ß√£o.
[2] ü§∞ **Mulher gr√°vida de 32 anos** - sua vida n√£o garante a do beb√™.

<br>ü§î ==Quem deve ser salvo?==



---
## Defini√ß√£o de justi√ßa üë©‚Äç‚öñÔ∏è

#### Complexa!

‚ñ∂ A no√ß√£o de justi√ßa **varia entre culturas e contextos**, refletindo valores e normas sociais.

‚ñ∂ Em IA, √© a busca por sistemas ==equitativos==, livres de discrimina√ß√£o ou vieses injustos.


---
# Equidade ‚â† Igualdade


A equidade considera **diferen√ßas individuais e estruturais**, garantindo que **todos tenham acesso √†s mesmas oportunidades**, mesmo que isso signifique **tratamentos diferenciados**. <br>

#### ‚öñÔ∏è Tratamentos diferentes podem ser necess√°rio para garantir justi√ßa! <br>

---
# Construindo um sistema "justo"

<small>(ver: <b>AI Blindspots</b> | MIT Media Lab)</small>

![bg](https://github.com/mmfava/my-social-media-content/blob/feature/slide-template/theme/slides-design/3.png?raw=true)

<!-- _class: first-slide -->

---
### 1Ô∏è‚É£ Prop√≥sito
<br>

‚ú∂ Prop√≥sito √© o norte!
‚ú∂ IA √© a melhor solu√ß√£o?
 ‚ú∂ Engajamento comunidade

 <small><small><small> ‚ö†Ô∏è  Sem prop√≥sito, pode gerar impactos negativos e desperd√≠cio de recursos.</small></small></small>

![bg right](figs/surto-ebola.png)

<br>
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Surto do Ebola (2014) - </strong>
Pesquisadores usaram dados de mobilidade para prever surtos, mas o Ebola se espalha por contato direto. O foco deveria ter sido <b>redes de contato entre infectados</b>.
</div>

---

### 2Ô∏è‚É£ Dados
<br>

==Vieses perpetuam desigualdade==
‚ú∂ Especialistas e comunidade
‚ú∂ Diversidade e qualidade
‚ú∂ Explorat√≥ria
‚ú∂ <u>Documenta√ß√£o</u>

<br>
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Liang et al. (2023) - </strong>Detectores de GPT est√£o enviesados contra "escritores" n√£o-nativos do ingl√™s.</b>
</div>

![bg right](figs/bias-writinh.png)

---

### 3Ô∏è‚É£ Abusabilidade
<br>

Uso **malicioso**!
<small><small>‚ö†Ô∏è  Deepfakes, manipula√ß√£o e desinforma√ß√£o</small></small> <br>
‚ú∂ Antecipar vulnerabilidades
‚ú∂ Criar cen√°rio hipot√©ticos 
‚ú∂ Processos de mitiga√ß√£o
‚ú∂ Processos de corre√ß√£o

<br>
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Poder 360 (24/01/2024) - </strong>Deep Fake do Papa Francisco usando casaco da moda e divulgado por grandes ve√≠culos de m√≠dia como verdade.  
<a href="https://www.poder360.com.br/internacional/alvo-de-deepfake-papa-pede-regulamentacao-de-ia/" target="_blank">[Link]</a>
</div>


![bg right](figs/papa-ai.png)

---
### 4Ô∏è‚É£ Privacidade

IA pode **comprometer a privacidade dos usu√°rios**.

‚ú∂ Seguran√ßa desde o design
‚ú∂ Avalia√ß√£o de risco de privacidade
‚ú∂ Consentimento dos usu√°rios 
‚ú∂ Aprimoramento de privacidade
 <small><small><small> üß∞ Aprendizado federado, privacidade diferencial, desidentifica√ß√£o e enclaves seguros de dados com base no n√≠vel de risco</small></small></small>

 
<br>
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>√âpoca Neg√≥cios (16/01/2025) - </strong>Brasileiros vendem registro da √≠ris por R$600 para projeto Worldcoin de Sam Altam, CEO da OpenAI
<a href="https://epocanegocios.globo.com/tecnologia/noticia/2025/01/brasileiros-vendem-registro-de-iris-por-r-600-entenda-como-funciona-o-processo-e-quais-os-riscos.ghtml" target="_blank">[Link]</a>
</div>

![bg right](figs/iris.png)

---

### 5Ô∏è‚É£ Proxy

<br>**Vi√©s oculto em vari√°veis correlacionadas**!
<small><small><small>‚ö†Ô∏è Um modelo pode **parecer neutro**, mas ainda refletir desigualdades.</small></small></small>
‚ú∂ Consultar especialistas 
‚ú∂ Remover features correlacionadas
‚ú∂ Testes

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;"> <strong>Ribeiro-Dantas et al. (2023) - </strong> O estado civil solteira foi indevidamente apontado como fator de risco para um tipo de c√¢ncer de mama. Os autores demonstram que a vari√°vel √© um proxy de fatores socioecon√¥micos, como acesso ao diagn√≥stico m√©dico adequado. </div>

![bg right](figs/cancer-mama.png)

---
### 6Ô∏è‚É£ Explicabilidade

<br>‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
Quem projeta e implementa sistemas algor√≠tmicos tem a ==responsabilidade de explicar decis√µes cr√≠ticas== que impactam o bem-estar das pessoas!
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è<br><br>

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">Usu√°rios precisam entender como e por que um algoritmo tomou uma decis√£o. Confian√ßa s√≥ existe quando h√° explicabilidade.</div>

![bg right](figs/black-box.png)

---

### 7Ô∏è‚É£ Otimiza√ß√£o
<br>

<small>==Desempenho sem equidade n√£o √© suficiente==!</small>
‚ú∂ *Trade-off* entre acur√°cia e equidade
‚ú∂ KPIs mensur√°veis 
‚ú∂ Monitoramento de m√©tricas

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;"> <strong>Shanklin et al. (2022) </strong> - O estudo mostra como algoritmos de IA podem perpetuar desigualdades raciais e prop√µe um m√©todo para equilibrar precis√£o e equidade, evitando discrimina√ß√£o sem comprometer a efici√™ncia. </div>

![bg right](figs/apontamento-medico.png)

---

### 8Ô∏è‚É£ Generaliza√ß√£o

==IA precisa se adaptar ao mundo real!==
‚ú∂ Mudan√ßas nos dados
‚ú∂ Processo de revis√£o humana 
‚ú∂ Alinhar expectativas 
‚ú∂ Metrifica√ß√£o 
‚ú∂ Planos de retreino e descontinuidade

![bg right](figs/blink.png)  

<br>  
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Time (22/01/2010) - </strong> C√¢meras da Nikon n√£o reconheciam corretamente rostos asi√°ticos, exibindo a mensagem "Algu√©m piscou?" mesmo com os olhos abertos.  
<a href="https://time.com/archive/6906847/are-face-detection-cameras-racist/" target="_blank">[Leia mais]</a>  
</div>  

---

### 9Ô∏è‚É£ Monitoramento


Decis√µes algor√≠tmicas devem ser **pass√≠veis de revis√£o** e **corre√ß√£o**
‚ú∂ Mecanismos de transpar√™ncia 
‚ú∂ Comunidade
‚ú∂ Documenta√ß√£o / Guia!
‚ú∂ Dashboards
‚ú∂ Regulamenta√ß√£o

![bg right](figs/monitorament.png)

---
# Reflex√µes finais

![bg](https://github.com/mmfava/my-social-media-content/blob/feature/slide-template/theme/slides-design/3.png?raw=true)

<!-- _class: first-slide -->


---
# Todos os modelos<br>==est√£o errados==

O importante √© reconhecer suas limita√ß√µes e mitig√°-las.


---
# A IA ==n√£o √© neutra==

Ela carrega os vieses e inten√ß√µes de quem a desenvolve e dos dados que a alimentam.  
O uso consciente exige entender essas influ√™ncias.

---
#  O vi√©s algor√≠tmico vai<br>==al√©m do t√©cnico==!

√â um problema social e √©tico que exige solu√ß√µes interdisciplinares e centradas no humano.

---
# Acur√°cia sem equidade √© ==insuficiente==.

Precisamos construir IA que seja n√£o apenas eficiente, mas tamb√©m justa.

---
# IA justa requer ==monitoramento== e ==contesta√ß√£o==.

Usu√°rios devem ter o direito de questionar decis√µes algor√≠tmicas e exigir transpar√™ncia.


---

### Refer√™ncias

1. Cheong, M. et al. (2024). _Investigating Gender and Racial Biases in DALL-E Mini Images_. [Online]. Available at: https://doi.org/10.1145/3649883 [Accessed 24 January 2025].
2. Choudhry, H. S. et al. (2023). _Perception of Race and Sex Diversity in Ophthalmology by Artificial Intelligence: A DALL E-2 Study_. [Online]. Available at: https://doi.org/10.2147/OPTH.S427296 [Accessed 24 January 2025].
3. Currie, G. et al. (2024). _Gender and Ethnicity Bias of Text-to-Image Generative Artificial Intelligence in Medical Imaging, Part 2: Analysis of DALL-E 3_. [Online]. Available at: https://doi.org/10.2967/jnmt.124.268359 [Accessed 24 January 2025].
4. Glickman, M. and Sharot, T. (2024). _How human‚ÄìAI feedback loops alter human perceptual, emotional and social judgements_. [Online]. Available at: https://www.nature.com/articles/s41562-024-02077-2 [Accessed 24 January 2025].
5.  Leslie, D. et al. (2021). _Does ‚ÄúAI‚Äù stand for augmenting inequality in the era of covid-19 healthcare?_ [Online]. Available at: https://doi.org/10.1136/bmj.n304 [Accessed 24 January 2025].
6. Liang, W. et al. (2023). _GPT detectors are biased against non-native English writers_. [Online]. Available at: https://doi.org/10.48550/arXiv.2304.02819 [Accessed 24 January 2025].


---

### Refer√™ncias
7. Luccioni, A. S. et al. (2023). _Stable Bias: Analyzing Societal Representations in Diffusion Models_. [Online]. Available at: https://doi.org/10.48550/arXiv.2303.11408 [Accessed 22 January 2025].
8. Mandal, A., Leavy, S. and Little, S. (2024). _Generated Bias: Auditing Internal Bias Dynamics of Text-To-Image Generative Models_. [Online]. Available at: https://doi.org/10.48550/arXiv.2410.07884 [Accessed 24 January 2025].
9. MIT Media Lab (2021). _AI Blindspot_. Dispon√≠vel em: [https://aiblindspot.media.mit.edu/index.html](https://aiblindspot.media.mit.edu/index.html) [Acesso em: 25 janeiro 2025].
10. Ribeiro-Dantas, M. da C. et al. (2023). _Learning interpretable causal networks from very large datasets, application to 400,000 medical records of breast cancer patients_. [Online]. Available at: https://doi.org/10.48550/arXiv.2303.06423 [Accessed 24 January 2025].
11. Shanklin, R. et al. (2022). _Ethical Redress of Racial Inequities in AI: Lessons from Decoupling Machine Learning from Optimization in Medical Appointment Scheduling_. [Online]. Available at: https://doi.org/10.1007/s13347-022-00590-8 [Accessed 24 January 2025].
12. Wu, Y., Nakashima, Y. and Garcia, N. (2024). _Gender Bias Evaluation in Text-to-image Generation: A Survey_. [Online]. Available at: https://doi.org/10.48550/arXiv.2408.11358 [Accessed 24 January 2025].


---
<!-- Texto Principal -->
<div class="texto-principal">Obrigada!</div>

<!-- Linha Divis√≥ria -->
<div class="linha"></div>
<div class="contato">
  <b>Mar√≠lia Melo Favalesso - PhD, Cientista de Dados<b>
</div>

<!-- Redes Sociais -->
<div class="redes-sociais">
  <a href="https://www.linkedin.com/in/seuusuario" target="_blank">üîó LinkedIn: /mariliafavalesso</a>
  <a href="mailto:seuemail@example.com">‚úâÔ∏è Email: marilia.melo.favalesso@gmail.com</a>
</div>

