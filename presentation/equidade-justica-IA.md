---
theme: slides-left
author: Mar√≠lia Melo Favalesso
_header: ""
header: üêç 82¬∫ Python Floripa
_footer: ""
_paginate: false
footer: Mar√≠lia Melo Favalesso
paginate: true
center: teste
date: ""
link: 
created: 2025-01-20T23:39
updated: 2025-01-25T00:10
---

<!-- _class: first-slide -->

<small>üêç 82¬∫ Python Floripa</small>

# Equidade e Justi√ßa em<br>Sistemas de IA

**Mar√≠lia Melo Favalesso**

---
## Mar√≠lia Melo Favalesso  

üß† Cientista de Dados | PhD

üêç Python e Comunidades  

üêà Gatos, pizza e bicicleta nas horas vagas

üîó LinkedIn: [/mariliafavalesso](https://www.linkedin.com/in/mariliafavalesso/)

üîó github: [/mmfava](https://github.com/mmfava)

---
# <!----fit-->O que estamos chamando de IA 

A **Intelig√™ncia Artificial (IA)** √© um termo abrangente que se refere a sistemas automatizados de tomada de decis√£o, capazes de executar tarefas que tradicionalmente exigiriam intelig√™ncia humana.


---

# O impacto das<br>==decis√µes algor√≠tmicas==

Embora aspirem imitar e automatizar o julgamento humano, a maioria dos algoritmos de IA s√£o, na verdade, **modelos imperfeitos suscet√≠veis a erros e vieses**.


---

## Proposta de experimento

‚ñ∂ Execute o seguinte prompt no chatGPT / DALL-E 3: 

**"Chat, pode gerar a imagem de uma pessoa lideran√ßa?"**<br>

<br> ü§î Qual foi o resultado? 


---

<style>
  .grid-container {
    display: grid;
    grid-template-columns: repeat(5, 1fr);
    gap: 10px;
  }
  .grid-container img {
    width: 100%;
    height: auto;
  }
</style>

<div class="grid-container">
  <img src="figs/e1.png">
  <img src="figs/e2.png">
  <img src="figs/e3.png">
  <img src="figs/e4.png">
  <img src="figs/e5.png">
  <img src="figs/e6.png">
  <img src="figs/e7.png">
  <img src="figs/e8.png">
  <img src="figs/e9.png">
  <img src="figs/e10.png">
</div>

<br>

<small><small>DALL-E 3 (OpenAI) ‚Üíüîó https://chatgpt.com/share/67915ff0-4c64-800e-b74e-176c169d355f</small></small>

---

## Proposta de experimento 2

‚ñ∂  Adicione ao prompt no chatGPT / DALL-E 3 a palavra "compassiva": 

**"Chat, pode gerar a imagem de uma pessoa lideran√ßa compassiva?"**

<br>ü§î Qual foi o resultado? 

---
<style>
  .grid-container {
    display: grid;
    grid-template-columns: repeat(5, 1fr);
    gap: 10px;
  }
  .grid-container img {
    width: 100%;
    height: auto;
  }
</style>

<div class="grid-container">
  <img src="figs/e2.1.png">
  <img src="figs/e2.2.png">
  <img src="figs/e2.3.png">
  <img src="figs/e2.4.png">
  <img src="figs/e2.5.png">
  <img src="figs/e2.6.png">
  <img src="figs/e2.7.png">
  <img src="figs/e2.8.png">
  <img src="figs/e2.9.png">
  <img src="figs/e2.10.png">
</div>

<br>

<small><small>DALL-E 3 (OpenAI) ‚Üíüîó https://chatgpt.com/share/6792b433-02b0-800e-8352-052e2fb2f531</small></small>

---
### Reflexo da realidade?
<br>


==N√ÉO!== Os modelos s√£o **enviesados**.


‚ú∂ Refor√ßam e amplificam estere√≥tipos existentes.
‚ú∂ Sub ou sobre-representam certos grupos.
‚ú∂ Podem levar a discrimina√ß√µes sist√™micas.

<br><small><small>**Ver:** Cheong et al. (2024), Currie et al. (2024), Mandal et al. (2024), Wu et al. (2024), Choudhry et al. (2023) e  Luccioni et al. (2023). </small></small>

<!---- 

Vi√©s em Intelig√™ncia Artificial (IA) refere-se a padr√µes sistem√°ticos de erro em modelos de aprendizado de m√°quina que levam a previs√µes ou decis√µes injustas, distorcidas ou discriminat√≥rias.

-->


---

#### Case 1: IA gerando imagens racistas

![bg right width:900px](figs/vereadora-discriminacao-ia.png)

<small><small><small>**G1 (26/10/2023)** - Deputada denuncia IA por gerar imagem racista quando solicitado um personagem negro em uma favela. (üîó[link](https://g1.globo.com/tecnologia/noticia/2023/10/26/deputada-do-rj-diz-que-robo-que-faz-desenhos-ao-estilo-pixar-entregou-imagem-de-mulher-negra-com-arma-na-mao-ao-receber-pedido-de-personagem-em-favela.ghtml)).</small></small></small>
<br>

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Prompt no <em>Bing Chat</em> da Microsoft (DALL-E):</strong><br>
"Uma mulher negra, de cabelos afro, com roupas de estampa africana num cen√°rio de favela".
</div>


---
#### Case 2: IA associando ra√ßa a crime

![bg left width:700px](figs/Imagem%20do%20WhatsApp%20de%202025-01-24%20√†(s)%2012.33.08_f345ba01.jpg)

<small><small><small>**Grupo LLM whatsapp (28/10/2024)** - IA da Meta gera imagem de um homem negro ao pedido de "pessoa que efetua atos errados na sociedade". </small></small></small>
<br>

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Prompt no <em>Meta AI</em> do Whatsapp:</strong><br>
"@Meta AI crie a imagem de uma pessoa que efetua atos errados na sociedade".
</div>

---
#### Case 3: IA associando ra√ßa a reincid√™ncia criminal

<small><small><small><mark>Old News!</mark><br>**ProPublica (23/05/2016)**: O artigo revela que o algoritmo COMPAS, usado no sistema judicial dos EUA para prever reincid√™ncia criminal, tem vi√©s racial: ele superestima o risco de reincid√™ncia para pessoas negras (mais falsos positivos) e subestima para pessoas brancas (mais falsos negativos) ([üîó link](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)).</small></small></small>
<br>

![bg right width:900px](figs/alto-risco-rei-crime.png)

---
### Reflexo da sociedade?

==SIM!== üèòÔ∏è ‚á¢ üë∂

As IA apresentam "**posicionalidade**"!

‚ú∂ Posicionalidade √© a forma como nossos **contextos sociais e pol√≠ticos moldam nossa percep√ß√£o do mundo**.

‚ú∂ Na IA, isso significa que **preconceitos e perspectivas humanas influenciam os sistemas de aprendizado de m√°quina**, pois refletem as escolhas feitas durante seu desenvolvimento.

---

![center width:1500px](figs/inequality-discrimination-covid.png)

<center><small><small><b>Ref:</b> Leslie et al. (2021)</small></small></center>

---
#### A IA amplifica vieses humanos

<small><small><b>Glickman and Sharot (2024)</b></small></small>
* IA refor√ßa vi√©s e influencia humanos a adot√°-lo.
* Maior vi√©s em intera√ß√µes humano-IA do que humano-humano.
* Percep√ß√£o da IA como neutra favorece aceita√ß√£o de vieses.
* IA imparciais podem melhorar julgamentos humanos.
![bg right width:900px](figs/muda-crenca.png)


---
# Mas o que √© ser <u>justo</u>?

‚ñ∂ **Responda:** 

H√° apenas um leito dispon√≠vel na UTI e dois pacientes em estado grave:

[1] üßí **Crian√ßa de 8 anos** - alta chance de recupera√ß√£o.
[2] ü§∞ **Mulher gr√°vida de 32 anos** - sua vida n√£o garante a do beb√™.

<br>==Quem deve receber o leito?==

---
# Mas o que √© ser <u>justo</u>?

‚ñ∂ **Responda:** 

H√° apenas um leito dispon√≠vel na UTI e dois pacientes em estado grave:

[1] üßî‚Äç‚ôÇÔ∏è **Homem de 40 anos** - baixa probabilidade de sobreviv√™ncia.
[2] üëµ **Mulher idosa de 75 anos** - probabilidade relativamente alta de sobreviv√™ncia.

<br>==Quem deve receber o leito?==

---
## Defini√ß√£o de justi√ßa üë©‚Äç‚öñÔ∏è

#### Complexa!

‚ñ∂ A no√ß√£o de justi√ßa **varia entre culturas e contextos**, refletindo valores e normas sociais.

‚ñ∂ Em IA, √© a busca por sistemas ==equitativos==, livres de discrimina√ß√£o ou vieses injustos.


---
# Equidade ‚â† Igualdade


A equidade considera **diferen√ßas individuais e estruturais**, garantindo que **todos tenham acesso √†s mesmas oportunidades**, mesmo que isso signifique **tratamentos diferenciados**.

#### Conceito bastante discutido, mas que tamb√©m n√£o √© f√°cil

---

# Construindo um sistema justo

_"Vi√©s algor√≠tmico n√£o √© um problema meramente t√©cnico, mas social e √©tico. Para mitig√°-lo, devemos agir desde a coleta de dados at√© a governan√ßa do sistema."_

‚Äî **Cathy O‚ÄôNeil**, autora de _Weapons of Math Destruction_

---
### 1Ô∏è‚É£ Prop√≥sito

IA deve ter um **objetivo claro** e ser a melhor solu√ß√£o para o problema. Sem um prop√≥sito bem definido, pode gerar impactos negativos e desperd√≠cio de recursos.

![bg right](figs/surto-ebola.png)

<br>
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Surto do Ebola (2014) - </strong>
Pesquisadores usaram dados de mobilidade para prever surtos, mas o Ebola se espalha por contato direto. O foco deveria ter sido <b>redes de contato entre infectados</b>.
</div>


---

### 2Ô∏è‚É£ Dados

Dados enviesados refor√ßam desigualdades. **√â necess√°rio garantir a diversidade com qualidade**. Auditorias e engajamento de especialistas s√£o consideradas boas pr√°ticas!

<br>
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Liang et al. (2023) - </strong>Detectores de GPT est√£o enviesados contra "escritores" n√£o-nativos do ingl√™s.</b>
</div>

![bg right](figs/bias-writinh.png)

---

### 3Ô∏è‚É£ Abusabilidade

Os desenvolvedores de IA precisam antecipar **vulnerabilidades e cen√°rios de uso indevido**. 

Algoritmos podem ser **sequestrados e transformados em ferramentas para fins maliciosos**, como manipula√ß√£o, vigil√¢ncia e desinforma√ß√£o.

<br>
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Poder 360 (24/01/2024) - </strong>Deep Fake do Papa Francisco usando casaco da moda e divulgado por grandes ve√≠culos de m√≠dia como verdade.  
<a href="https://www.poder360.com.br/internacional/alvo-de-deepfake-papa-pede-regulamentacao-de-ia/" target="_blank">[Link]</a>
</div>


![bg right](figs/papa-ai.png)

---
### 4Ô∏è‚É£ Privacidade

Os sistemas de IA podem comprometer a **privacidade** dos usu√°rios ao armazenar dados sens√≠veis, sujeitos a vazamentos e ataques. 

Para mitigar riscos, √© essencial aplicar **seguran√ßa desde o design** e garantir o **controle do usu√°rio** sobre seus dados.

<br>
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>√âpoca Neg√≥cios (16/01/2025) - </strong>Brasileiros vendem registro da √≠ris por R$600 para projeto Worldcoin de Sam Altam, CEO da OpenAI
<a href="https://epocanegocios.globo.com/tecnologia/noticia/2025/01/brasileiros-vendem-registro-de-iris-por-r-600-entenda-como-funciona-o-processo-e-quais-os-riscos.ghtml" target="_blank">[Link]</a>
</div>

![bg right](figs/iris.png)

---

### 5Ô∏è‚É£ Proxy

Algoritmos podem discriminar **indiretamente** ao usar vari√°veis correlacionadas a **atributos protegidos**, como ra√ßa ou g√™nero.

√â de extrema import√¢ncia a consulta a especialistas no assunto! <br>

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;"> <strong>Ribeiro-Dantas et al. (2023) - </strong> O estado civil solteira foi indevidamente apontado como fator de risco para um tipo de c√¢ncer de mama. Os autores demonstram que a vari√°vel √© um proxy de fatores socioecon√¥micos, como acesso ao diagn√≥stico m√©dico adequado. </div>

![bg right](figs/cancer-mama.png)

---
### 6Ô∏è‚É£ Explicabilidade

Quem projeta e implementa sistemas algor√≠tmicos tem a **responsabilidade de explicar decis√µes cr√≠ticas** que impactam o bem-estar das pessoas.

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;"> O usu√°rio quer entender o motivo dos resultados, o motivo das falhas e quando e o quanto ele pode confiar na IA!</div>

![bg right](figs/black-box.png)

---

#### Interpretabilidade

Refere-se √† capacidade de entender como um modelo de IA funciona e chega √†s suas conclus√µes.<br>
**Um modelo interpret√°vel permite rastrear o impacto de cada entrada na sa√≠da.**
<br><small><small>[üîó Link da figura](https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.html)</small></small>

![bg left width:1000px](figs/interpretabilidade.png)


---
#### Explicabilidade

Conjunto de processos e m√©todos que permite que usu√°rios humanos **compreendam e confiem nos resultados e sa√≠das** criados por algoritmos de aprendizado de m√°quina.
<br><small><small>[üîó Link da figura](https://media.geeksforgeeks.org/wp-content/uploads/20231201153509/Explainable-AI-Concept-1-660.png)</small></small>

![bg left width:900px](figs/shap-local-global.png)


---

### 7Ô∏è‚É£ Otimiza√ß√£o

Definir m√©tricas de sucesso para IA envolve **compensa√ß√µes e impactos colaterais**. √â essencial equilibrar **desempenho e equidade**, minimizando riscos para popula√ß√µes vulner√°veis.

<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;"> <strong>Shanklin et al. (2022) </strong> - O estudo mostra como algoritmos de IA podem perpetuar desigualdades raciais e prop√µe um m√©todo para equilibrar precis√£o e equidade, evitando discrimina√ß√£o sem comprometer a efici√™ncia. </div>

![bg right](figs/apontamento-medico.png)

---

### 8Ô∏è‚É£ Generaliza√ß√£o

Entre o desenvolvimento e a implementa√ß√£o de um sistema de IA, **o mundo ‚Äì e os usu√°rios ‚Äì podem mudar**, tornando o contexto original inadequado e levando a falhas inesperadas.  

Planos de retreino e descontinuidade s√£o necess√°rios! 

![bg right](figs/blink.png)  

<br>  
<div style="border: 1px solid #ccc; padding: 20px; padding-left:60px; font-size: 0.7em; background-color: #f8f8f8;">
<strong>Time (22/01/2010) - </strong> C√¢meras da Nikon n√£o reconheciam corretamente rostos asi√°ticos, exibindo a mensagem "Algu√©m piscou?" mesmo com os olhos abertos.  
<a href="https://time.com/archive/6906847/are-face-detection-cameras-racist/" target="_blank">[Leia mais]</a>  
</div>  

---

### 9Ô∏è‚É£ Monitoramento

Decis√µes algor√≠tmicas devem ser **pass√≠veis de revis√£o**, garantindo que indiv√≠duos possam **question√°-las e corrigi-las**. 

Al√©m disso, **monitoramento cont√≠nuo e transpar√™ncia** s√£o essenciais para evitar abusos e garantir responsabilidade no uso da IA.

![bg right](figs/monitorament.png)


---
**Reflex√µes finais**

# A IA ==n√£o √© neutra== ‚Äì ela reflete as escolhas de quem a constr√≥i e os dados que a alimentam!

---
**Reflex√µes finais**

#  Vi√©s algor√≠tmico n√£o √© apenas um problema t√©cnico,<br>mas ==social e √©tico==. 

A mitiga√ß√£o exige um olhar interdisciplinar.

---
**Reflex√µes finais**

# Precisamos equilibrar ==acur√°cia e equidade==, garantindo que sistemas de IA sejam justos e transparentes.

---
**Reflex√µes finais**

# A supervis√£o cont√≠nua e o direito √† contesta√ß√£o s√£o fundamentais para que a IA beneficie a sociedade sem refor√ßar desigualdades!


---

### Refer√™ncias

1. Cheong, M. et al. (2024). _Investigating Gender and Racial Biases in DALL-E Mini Images_. [Online]. Available at: https://doi.org/10.1145/3649883 [Accessed 24 January 2025].
2. Choudhry, H. S. et al. (2023). _Perception of Race and Sex Diversity in Ophthalmology by Artificial Intelligence: A DALL E-2 Study_. [Online]. Available at: https://doi.org/10.2147/OPTH.S427296 [Accessed 24 January 2025].
3. Currie, G. et al. (2024). _Gender and Ethnicity Bias of Text-to-Image Generative Artificial Intelligence in Medical Imaging, Part 2: Analysis of DALL-E 3_. [Online]. Available at: https://doi.org/10.2967/jnmt.124.268359 [Accessed 24 January 2025].
4. Glickman, M. and Sharot, T. (2024). _How human‚ÄìAI feedback loops alter human perceptual, emotional and social judgements_. [Online]. Available at: https://www.nature.com/articles/s41562-024-02077-2 [Accessed 24 January 2025].
5.  Leslie, D. et al. (2021). _Does ‚ÄúAI‚Äù stand for augmenting inequality in the era of covid-19 healthcare?_ [Online]. Available at: https://doi.org/10.1136/bmj.n304 [Accessed 24 January 2025].
6. Liang, W. et al. (2023). _GPT detectors are biased against non-native English writers_. [Online]. Available at: https://doi.org/10.48550/arXiv.2304.02819 [Accessed 24 January 2025].


---

### Refer√™ncias
7. Luccioni, A. S. et al. (2023). _Stable Bias: Analyzing Societal Representations in Diffusion Models_. [Online]. Available at: https://doi.org/10.48550/arXiv.2303.11408 [Accessed 22 January 2025].
8. Mandal, A., Leavy, S. and Little, S. (2024). _Generated Bias: Auditing Internal Bias Dynamics of Text-To-Image Generative Models_. [Online]. Available at: https://doi.org/10.48550/arXiv.2410.07884 [Accessed 24 January 2025].
9. Ribeiro-Dantas, M. da C. et al. (2023). _Learning interpretable causal networks from very large datasets, application to 400,000 medical records of breast cancer patients_. [Online]. Available at: https://doi.org/10.48550/arXiv.2303.06423 [Accessed 24 January 2025].
10. Shanklin, R. et al. (2022). _Ethical Redress of Racial Inequities in AI: Lessons from Decoupling Machine Learning from Optimization in Medical Appointment Scheduling_. [Online]. Available at: https://doi.org/10.1007/s13347-022-00590-8 [Accessed 24 January 2025].
11. Wu, Y., Nakashima, Y. and Garcia, N. (2024). _Gender Bias Evaluation in Text-to-image Generation: A Survey_. [Online]. Available at: https://doi.org/10.48550/arXiv.2408.11358 [Accessed 24 January 2025].


---
<!-- Texto Principal -->
<div class="texto-principal">Obrigada!</div>

<!-- Linha Divis√≥ria -->
<div class="linha"></div>
<div class="contato">
  <b>Mar√≠lia Melo Favalesso - PhD, Cientista de Dados<b>
</div>

<!-- Redes Sociais -->
<div class="redes-sociais">
  <a href="https://www.linkedin.com/in/seuusuario" target="_blank">üîó LinkedIn: /mariliafavalesso</a>
  <a href="mailto:seuemail@example.com">‚úâÔ∏è Email: marilia.melo.favalesso@gmail.com</a>
</div>

