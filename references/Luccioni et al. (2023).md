---
created: 2025-01-22T18:26
updated: 2025-01-22T19:12
group: papers
title: "Stable Bias: Evaluating Societal Representations in Diffusion Models"
authors:
  - Alexandra Sasha Luccioni
  - Christopher Akiki
  - Margaret Mitchell
  - Yacine Jernite
publisher: Neural Information Processing Systems (NeurIPS) 2023 ‚Äì Datasets and Benchmarks Track
year: 2023
journal: NeurIPS 2023 ‚Äì Datasets and Benchmarks Track
institution:
  - Hugging Face, Canada
  - Leipzig University and ScaDS.AI
  - Hugging Face, USA
doi: https://doi.org/10.48550/arXiv.2303.11408
abstract: |
  O estudo avalia os vieses sociais embutidos em modelos de difus√£o para gera√ß√£o de imagens a partir de texto (*text-to-image*). A abordagem compara imagens geradas com varia√ß√£o em atributos de identidade, como g√™nero e etnia, e analisa a representatividade dos modelos Stable Diffusion v1.4, v2 e DALL¬∑E 2. Os resultados indicam sub-representa√ß√£o de mulheres e minorias raciais, com implica√ß√µes para equidade e transpar√™ncia em IA.
tags:
  - Bias
  - in
  - AI
  - Text-to-Image
  - Models
  - Stable
  - Diffusion
  - DALL¬∑E
  - Machine
  - Learning
  - Ethics
  - Representation
  - in
  - AI
link: https://openreview.net/pdf?id=qVXYU3F017
---


### **M√©todos**

O estudo prop√µe uma abordagem para quantificar vieses sociais nos modelos de gera√ß√£o de imagens por difus√£o, analisando a varia√ß√£o das imagens geradas com base em atributos de identidade como g√™nero e etnia. O m√©todo segue os seguintes passos:

1. **Gera√ß√£o de Dataset**
    
    - Foram usados prompts padronizados no formato _"Photo portrait of a [X] [Y] at work"_, onde _X_ representa etnia e _Y_ representa g√™nero.
    - Foram utilizados 68 combina√ß√µes de g√™nero (homem, mulher, n√£o-bin√°rio, e neutro) e etnia (baseado no censo dos EUA).
    - Os modelos analisados foram:
        - **Stable Diffusion v1.4**
        - **Stable Diffusion v2**
        - **DALL¬∑E 2**
    - Al√©m disso, foi criada uma segunda base de dados com imagens geradas para 146 profiss√µes, baseadas na classifica√ß√£o do Bureau of Labor Statistics (BLS) dos EUA.
2. **An√°lise dos Vieses nas Imagens**
    
    - Foram utilizadas **duas abordagens principais** para avalia√ß√£o das imagens:
        1. **An√°lise baseada em texto**:
            - Uso de modelos de _Image Captioning_ e _Visual Question Answering (VQA)_ para gerar descri√ß√µes das imagens.
            - Foram analisadas palavras-chave associadas a g√™nero e etnia.
        2. **An√°lise baseada em imagens**:
            - Uso de **t√©cnicas de clustering** para agrupar imagens em espa√ßos de representa√ß√£o multimodal, permitindo avaliar a distribui√ß√£o de diferentes grupos.
            - Para isso, utilizaram embeddings extra√≠dos pelo modelo BLIP VQA.
3. **Compara√ß√£o com Dados Demogr√°ficos**
    
    - Os resultados foram comparados com as estat√≠sticas de g√™nero e etnia para cada profiss√£o segundo os dados do BLS.
    - Isso permitiu avaliar se os modelos reproduziam ou distorciam as propor√ß√µes reais dessas categorias no mercado de trabalho.
4. **Explora√ß√£o Interativa**
    
    - Foram desenvolvidas ferramentas para facilitar a an√°lise interativa dos dados:
        - _Diffusion Bias Explorer_: compara as imagens geradas pelos diferentes modelos.
        - _Average Face Comparison Tool_: gera uma m√©dia visual das faces representadas em cada profiss√£o.
        - _k-NN Explorer_: permite explorar imagens por similaridade visual.

### **Principais Resultados**

Os resultados mostram que os modelos apresentam vieses sistem√°ticos em suas representa√ß√µes de g√™nero e etnia. Algumas descobertas importantes:

1. **Sub-representa√ß√£o de Mulheres e Grupos Raciais Minorit√°rios**
    
    - Em todos os modelos, a propor√ß√£o de imagens de mulheres e de pessoas negras geradas para profiss√µes espec√≠ficas √© menor do que os dados reais do mercado de trabalho.
    - O modelo **DALL¬∑E 2** apresentou os maiores desvios, enquanto o **Stable Diffusion v1.4** teve os desvios menos acentuados.
2. **Diferen√ßas entre Modelos**
    
    - O **Stable Diffusion v1.4** gerou distribui√ß√µes mais pr√≥ximas das estat√≠sticas reais do BLS.
    - O **DALL¬∑E 2** teve um vi√©s maior, frequentemente gerando imagens majoritariamente masculinas e brancas.
    - O **Stable Diffusion v2** apresentou uma tend√™ncia intermedi√°ria entre os dois modelos anteriores.
3. **Profiss√µes mais Afetadas por Vi√©s de G√™nero**
    
    - Algumas profiss√µes que, segundo o BLS, possuem alta presen√ßa feminina (como enfermeiras e professores) foram sub-representadas nos modelos.
    - Profiss√µes tradicionalmente masculinas (como CEO e engenheiro) tiveram representa√ß√µes ainda mais dominadas por imagens masculinas.
4. **An√°lises Quantitativas dos Vieses**
    
    - Cerca de **97,66% das legendas geradas por modelos de Image Captioning** continham marcadores de g√™nero, demonstrando que os modelos incorporam fortemente categorias sociais em suas representa√ß√µes.
    - A distribui√ß√£o de g√™nero nas imagens geradas ficou **9% a 27% abaixo** dos valores reais do BLS, dependendo do modelo analisado.
5. **Distribui√ß√£o Visual de G√™nero e Etnia**
    
    - Usando a abordagem de _clustering_, foi poss√≠vel identificar que imagens de **homens brancos** eram dominantes nas representa√ß√µes geradas.
    - Regi√µes associadas a **mulheres** e **pessoas negras** eram sistematicamente menos representadas, especialmente em profiss√µes onde esses grupos s√£o historicamente minorit√°rios.

### **Conclus√£o e Implica√ß√µes**

- O estudo evidencia que os modelos de gera√ß√£o de imagens baseados em difus√£o apresentam vieses que refletem e amplificam desigualdades sociais.
- Esses vieses podem ter impactos significativos quando os modelos s√£o utilizados em contextos profissionais, art√≠sticos e comerciais, contribuindo para a marginaliza√ß√£o de grupos sub-representados.
- Os autores disponibilizaram ferramentas para permitir a auditoria de vieses em outros modelos de gera√ß√£o de imagens.

## **Implica√ß√µes Pr√°ticas do Estudo**

### **1. Impacto na Ind√∫stria de Intelig√™ncia Artificial e Empresas de Tecnologia**

- **Melhoria na Transpar√™ncia e Auditoria de Modelos**: Empresas que desenvolvem modelos de _text-to-image_ (TTI) podem usar a metodologia proposta para identificar e mitigar vieses em seus modelos antes de disponibiliz√°-los para o p√∫blico.
- **Tomada de Decis√£o na Escolha de Modelos**: Empresas que utilizam modelos como _Stable Diffusion_ ou _DALL¬∑E 2_ para gerar imagens comerciais podem usar a abordagem do estudo para escolher modelos menos enviesados ou aplicar t√©cnicas de corre√ß√£o.
- **Evolu√ß√£o de Ferramentas de Controle de Vi√©s**: A pesquisa refor√ßa a necessidade de novas abordagens para reduzir a perpetua√ß√£o de estere√≥tipos e desigualdades na gera√ß√£o de imagens.

### **2. Impacto em Aplica√ß√µes Comerciais e Criativas**

Os modelos de gera√ß√£o de imagens s√£o amplamente utilizados em diversas aplica√ß√µes, e os vieses descobertos podem ter impactos negativos nesses contextos:

- **Publicidade e Marketing**:
    
    - Se os modelos geram predominantemente imagens de homens brancos para certas profiss√µes, isso pode refor√ßar estere√≥tipos e afetar campanhas publicit√°rias que buscam representar a diversidade do p√∫blico-alvo.
    - Empresas podem precisar ajustar manualmente as imagens geradas ou desenvolver estrat√©gias para garantir maior representatividade.
- **Ind√∫stria de Entretenimento e Design Gr√°fico**:
    
    - Profissionais de cria√ß√£o podem depender desses modelos para gerar arte conceitual, ilustra√ß√µes e conte√∫do visual.
    - O vi√©s nos modelos pode limitar a diversidade nas cria√ß√µes, refor√ßando uma vis√£o de mundo homog√™nea e pouco representativa.
- **Educa√ß√£o e M√≠dia**:
    
    - Plataformas educacionais e ve√≠culos de comunica√ß√£o que utilizam IA para criar conte√∫do visual podem, sem querer, propagar representa√ß√µes estereotipadas de g√™nero e etnia.

### **3. Riscos para Inclus√£o e Representatividade**

- **Sub-representa√ß√£o de Grupos Marginalizados**:
    
    - O estudo mostrou que mulheres e pessoas negras s√£o menos representadas nas imagens geradas, especialmente em profiss√µes onde elas j√° s√£o minorit√°rias.
    - Isso pode impactar a autoimagem e a percep√ß√£o de oportunidades de carreira para pessoas pertencentes a esses grupos.
- **Amplifica√ß√£o de Discrimina√ß√£o e Estere√≥tipos**:
    
    - Se os modelos continuam a refor√ßar estere√≥tipos de g√™nero e ra√ßa (por exemplo, associando profiss√µes de alta renda a homens brancos), podem contribuir para a normaliza√ß√£o desses padr√µes na sociedade.

### **4. Implica√ß√µes Reguladoras e √âticas**

- **Necessidade de Normas e Padr√µes para Modelos de IA**:
    
    - Reguladores podem usar essa pesquisa como base para estabelecer padr√µes de transpar√™ncia e mitiga√ß√£o de vi√©s para modelos de IA.
    - Ferramentas de auditoria baseadas na metodologia do estudo podem se tornar um requisito legal em setores como publicidade, contrata√ß√£o e educa√ß√£o.
- **Desafios na Regula√ß√£o de Modelos de C√≥digo Aberto**:
    
    - Enquanto modelos fechados como o _DALL¬∑E 2_ podem ser ajustados pelos desenvolvedores para reduzir vi√©s, modelos abertos como _Stable Diffusion_ podem ser treinados ou ajustados por qualquer pessoa, tornando a mitiga√ß√£o de vi√©s mais dif√≠cil.
    - Pol√≠ticas p√∫blicas podem precisar considerar como balancear inova√ß√£o e responsabilidade social no uso de modelos abertos.

### **5. Desenvolvimento de Novas Ferramentas e M√©todos de Mitiga√ß√£o**

- **Ado√ß√£o de T√©cnicas de Ajuste e Fine-Tuning**:
    
    - Empresas e pesquisadores podem desenvolver ajustes nos modelos para balancear melhor as representa√ß√µes de g√™nero e etnia.
    - T√©cnicas de _prompt engineering_ podem ser refinadas para melhorar a diversidade nas imagens geradas.
- **Ferramentas de Auditoria e Monitoramento**:
    
    - As ferramentas desenvolvidas no estudo, como _Diffusion Bias Explorer_ e _Average Face Comparison Tool_, podem ser usadas por desenvolvedores e reguladores para monitorar vieses em novos modelos de IA.

 -------

Aqui est√° a tradu√ß√£o do texto para o portugu√™s:

---

### **Vi√©s Est√°vel: Avaliando Representa√ß√µes Sociais em Modelos de Difus√£o**

Esta pesquisa foca na avalia√ß√£o das representa√ß√µes sociais em sistemas de **Texto para Imagem (TTI)** para compreender e mitigar vieses em tecnologias de aprendizado de m√°quina. O estudo introduz um m√©todo inovador para analisar vieses nesses sistemas, examinando as varia√ß√µes nas imagens geradas com base em **g√™nero, marcadores √©tnicos e profiss√µes**, permitindo a identifica√ß√£o de tend√™ncias espec√≠ficas de vi√©s e fornecendo escores comparativos de diversidade. Os resultados revelam que os principais sistemas de TTI apresentam correla√ß√µes com a demografia do mercado de trabalho dos EUA, mas sub-representam consistentemente **identidades marginalizadas**, ressaltando a import√¢ncia de abordar o vi√©s em modelos de intelig√™ncia artificial para melhorar a inclus√£o social.

---

### **Introdu√ß√£o**

A introdu√ß√£o discute o avan√ßo dos modelos baseados em difus√£o no **Aprendizado de M√°quina (ML)**, principalmente na gera√ß√£o de imagens a partir de texto, destacando modelos como **Stable Diffusion, Make-a-Scene, Imagen e DALL¬∑E 2**, que ganharam popularidade rapidamente. Os principais pontos abordados s√£o:

- Modelos de difus√£o s√£o inspirados em princ√≠pios da **termodin√¢mica fora de equil√≠brio** e treinados para reduzir gradualmente o ru√≠do em imagens.
- Sua **fun√ß√£o de perda baseada em verossimilhan√ßa** torna o treinamento mais simples e os resultados mais diversos.
- A an√°lise do **espa√ßo latente** desses modelos √© dif√≠cil devido ao seu treinamento iterativo.
- Modelos TTI incluem **m√∫ltiplas fases de processamento de texto e imagem**.
- Esses sistemas est√£o se tornando **onipresentes em v√°rias aplica√ß√µes**, podendo **perpetuar vieses sociais**.
- H√° **pouca documenta√ß√£o detalhada** sobre os vieses nos sistemas TTI, dificultando sua auditoria.
- O artigo introduz ferramentas para **auditar vieses sociais**, comparando sa√≠das de modelos baseadas em prompts espec√≠ficos.
- A pesquisa compara os vieses sociais incorporados nos modelos **Stable Diffusion v1.4, v2 e DALL¬∑E 2** em rela√ß√£o a diferentes profiss√µes e palavras-chave de g√™nero/etnia.
- S√£o fornecidas ferramentas para explorar outros sistemas TTI e analisar conjuntos de dados gerados para profiss√µes.
- A conclus√£o aborda **as implica√ß√µes da pesquisa e sugere dire√ß√µes futuras para investiga√ß√µes adicionais**.

---

### **Contextualiza√ß√£o**

O vi√©s em aprendizado de m√°quina (ML) envolve:

- Diferen√ßas no desempenho do modelo para diferentes categorias;
- Propaga√ß√£o de estere√≥tipos sociais;
- Representa√ß√µes problem√°ticas nos conjuntos de dados que influenciam as sa√≠das do modelo e as percep√ß√µes dos usu√°rios.

Principais aspectos abordados:

- Estudos anteriores analisaram vieses em ML, com contribui√ß√µes de diversas √°reas, incluindo **ci√™ncias sociais, cognitivas, direito e pol√≠ticas p√∫blicas**.
- O projeto se baseia nesses trabalhos para expandir os conhecimentos sobre vi√©s em ML.
- Tr√™s dimens√µes principais s√£o consideradas:
    1. **Diferen√ßa de desempenho dos modelos entre categorias sociais**;
    2. **Propaga√ß√£o de estere√≥tipos**;
    3. **Problemas de representatividade em datasets usados para treinar os modelos**.

---

### **Avalia√ß√£o de Vi√©s em Modelos Multimodais**

A pesquisa explora vieses em modelos **multimodais**, que combinam **texto e imagem**. Os principais pontos s√£o:

- **Desafios na compreens√£o do vi√©s**: Estudos anteriores focaram separadamente em modelos de texto e imagem, mas o crescimento dos modelos multimodais superou o desenvolvimento de m√©todos para an√°lise de vi√©s.
- **Amplifica√ß√£o de vi√©s**: Ainda n√£o est√° claro se os vieses de diferentes modalidades se somam ou amplificam um ao outro.
- **Exemplo de vi√©s composto**: Um modelo pode representar ‚Äúpessoas‚Äù e ‚Äúpessoas brancas‚Äù de maneira visualmente distinta, ao mesmo tempo que associa ‚Äúpessoas‚Äù a termos positivos e ‚Äúpessoas negras‚Äù a termos negativos.
- **Evid√™ncias de vi√©s**: Pesquisas anteriores mostraram que modelos multimodais tendem a perpetuar **estere√≥tipos sociais sobre ra√ßa, g√™nero e apar√™ncia**.
- **Exemplos pr√°ticos**:
    - Modelos de IA associam **mulheres a compras** e **homens a esportes radicais**.
    - Modelos geram descri√ß√µes de menor qualidade para **pessoas de pele escura**.
    - Algoritmos de busca de imagens refor√ßam vieses ao mostrar **mais imagens de homens brancos** para profiss√µes prestigiadas.

---

### **Sistemas Texto-para-Imagem e seus Vieses**

Os sistemas TTI se tornaram populares, motivando pesquisas sobre:

- Filtros de seguran√ßa e seu funcionamento;
- Estrutura sem√¢ntica dos modelos;
- Gera√ß√£o de **representa√ß√µes estereotipadas** de diferentes grupos demogr√°ficos;
- Memoriza√ß√£o e reprodu√ß√£o de exemplos espec√≠ficos do conjunto de treinamento.

Algumas das principais descobertas incluem:

- Modelos como **CLIP**, que orientam a difus√£o, j√° codificam **vieses raciais e culturais**.
- Dados de treinamento s√£o retirados da internet e **cont√™m conte√∫do problem√°tico, como pornografia e informa√ß√µes incorretas**.
- Aplica√ß√£o de **filtros de seguran√ßa** pode **exacerbar vieses**, como foi observado no DALL¬∑E 2.

---

### **Metodologia: Auditoria de Vieses Sociais em Sistemas TTI**

Os pesquisadores prop√µem uma nova abordagem para medir vieses nos modelos TTI. Os passos s√£o:

1. **Definir caracter√≠sticas de identidade**: O estudo foca em **g√™nero e etnia**.
2. **Gerar imagens com varia√ß√µes nesses atributos**: Utilizam prompts padronizados como:
    - _"Retrato fotogr√°fico de um [etnia] [g√™nero] no trabalho."_
3. **Criar conjuntos de dados**:
    - **Dataset de identidades**: 68 combina√ß√µes de etnia e g√™nero.
    - **Dataset de profiss√µes**: 146 profiss√µes baseadas no Bureau of Labor Statistics (BLS).
4. **Analisar as imagens geradas**:
    - **An√°lise baseada em texto** (usando modelos de _Visual Question Answering_ e _Image Captioning_).
    - **An√°lise baseada em imagens** (t√©cnicas de _clustering_ para agrupar imagens com caracter√≠sticas similares).

---

### **Principais Resultados**

1. **Sub-representa√ß√£o de mulheres e grupos raciais marginalizados**:
    
    - Todos os modelos analisados geraram **menos imagens de mulheres e pessoas negras** do que os dados reais do mercado de trabalho.
    - O **DALL¬∑E 2** apresentou o maior vi√©s, enquanto o **Stable Diffusion v1.4** foi o mais balanceado.
2. **Discrep√¢ncias nas profiss√µes**:
    
    - Algumas profiss√µes com alta presen√ßa feminina no mercado de trabalho, como **enfermeiras e professoras**, foram **sub-representadas** nos modelos.
    - Profiss√µes como **CEO e engenheiro** apresentaram uma **propor√ß√£o ainda maior de homens brancos** do que os dados reais indicam.
3. **Impacto dos filtros de seguran√ßa**:
    
    - A tentativa de **remover conte√∫dos expl√≠citos** do treinamento do DALL¬∑E 2 **ampliou desigualdades de representa√ß√£o**, reduzindo a presen√ßa de **mulheres e grupos raciais minorit√°rios**.

---

### **Conclus√µes e Implica√ß√µes Pr√°ticas**

- **Regulamenta√ß√£o e transpar√™ncia**: As empresas devem desenvolver estrat√©gias para auditar e reduzir vieses em IA.
- **Impacto em publicidade e m√≠dia**: Modelos enviesados podem refor√ßar **estere√≥tipos de g√™nero e ra√ßa**.
- **Evolu√ß√£o de ferramentas de IA**: Novas t√©cnicas devem ser desenvolvidas para tornar os modelos mais representativos.
- **Padr√µes √©ticos**: O estudo destaca a necessidade de diretrizes para que a IA seja mais **justa e inclusiva**.

---

Se precisar de mais detalhes ou ajustes, me avise! üòä