---
url: https://www.youtube.com/watch?v=w_3L1Bf2P_g
title: Introduction to Responsible AI
channel: Google Cloud
thumbnailUrl: https://i.ytimg.com/vi/w_3L1Bf2P_g/maxresdefault.jpg
duration: "578"
tags:
  - machine-learning
  - artificial-intelligence
  - applied-ml
  - ml-in-production
alias: Responsable-AI-Google
published: 2024-04-08
created: 2025-01-22T13:36:14-03:00
watched: false
genre: Science & Technology
Youtube_ID: w_3L1Bf2P_g
updated: 2025-01-22T19:12
group: youtube
---
Aqui está a tradução das informações para o português:

---

## Sobre

**Tipo:** Vídeo do YouTube

![Introdução à IA Responsável](https://www.youtube.com/watch?v=w_3L1Bf2P_g)

### Descrição

No Google, levamos a IA responsável a sério. Descubra por que a IA responsável é mais importante do que nunca e por que nos preocupamos tanto com isso. Explore os 7 Princípios de IA do Google, um framework projetado para guiar os usuários em direção a um uso mais seguro e ético da IA.

Acesse o Google Cloud Skills Boost para se inscrever gratuitamente neste curso! → [https://goo.gle/3CGhlXo](https://goo.gle/3CGhlXo)

Inscreva-se AQUI: [youtube.com/googlecloud](https://youtube.com/googlecloud)

#IAGenerativa #computacaonuvem #aprendizadoGoogleCloud


# Transcrição

A inteligência artificial está sendo amplamente discutida, mas o que significa usar IA de forma responsável? Se você não tem certeza, ótimo, estou aqui para isso. Meu nome é Manny e sou engenheiro de segurança no Google. Vou te ensinar a:

- Compreender por que o Google estabeleceu princípios de IA;
- Identificar a necessidade de práticas responsáveis de IA dentro de uma organização;
- Reconhecer que a IA responsável afeta todas as decisões em todas as fases de um projeto;
- Entender que as organizações podem projetar suas ferramentas de IA de acordo com suas necessidades e valores de negócios.

Parece bom? Então vamos lá.

Você pode não perceber, mas muitos de nós já interagimos com inteligência artificial (IA) diariamente, seja em previsões de tráfego e clima ou em recomendações de programas de TV para assistir. À medida que a IA se torna mais comum, tecnologias que não utilizam IA começam a parecer ultrapassadas, como ter um telefone que não acessa a internet.

Os sistemas de IA estão permitindo que computadores vejam, compreendam e interajam com o mundo de formas que eram inimagináveis há uma década. E esses sistemas estão evoluindo em um ritmo extraordinário. No entanto, apesar desses avanços notáveis, a IA não é infalível. Desenvolver uma IA responsável exige compreensão sobre possíveis problemas, limitações e consequências não intencionais.

A tecnologia reflete a sociedade em que existe. Sem boas práticas, a IA pode replicar problemas existentes, como viés, e até amplificá-los. Isso torna as coisas complicadas, pois não há uma definição universal de IA responsável nem um checklist simples para sua implementação. Em vez disso, as organizações desenvolvem seus próprios princípios de IA para refletir sua missão e valores.

Felizmente, apesar de cada organização ter princípios únicos, há temas comuns: transparência, justiça, responsabilidade e privacidade.

### Como o Google vê a IA responsável?

Nosso compromisso com a IA responsável se baseia em:

- Criar IA para todos;
- Garantir segurança e responsabilidade;
- Respeitar a privacidade;
- Ser impulsionada pela excelência científica.

Desenvolvemos nossos próprios princípios, práticas, processos de governança e ferramentas para guiar nossa abordagem à IA responsável. Incorporamos a responsabilidade desde o design dos nossos produtos e, mais importante ainda, na organização.

Como muitas empresas, usamos nossos princípios de IA como um guia para a tomada de decisões responsáveis. Todos têm um papel na forma como a IA é aplicada. Em qualquer estágio do processo – do design à implementação – as decisões impactam o resultado final. Por isso, é essencial que cada organização tenha um processo bem definido e repetível para garantir o uso responsável da IA.

Há um equívoco comum de que máquinas tomam as decisões centrais na IA. Na realidade, são as pessoas que projetam, constroem e decidem como usá-las. Elas escolhem os dados de treinamento, controlam o uso da IA e influenciam o impacto do modelo. Em cada decisão, valores humanos são incorporados.

Isso significa que cada etapa exige consideração e avaliação para garantir que as escolhas sejam feitas de forma responsável, desde o conceito até a manutenção da IA. Como a IA pode impactar diversos setores e a vida das pessoas, é essencial desenvolvê-la com ética.

### Os 7 Princípios de IA do Google

Em junho de 2018, anunciamos sete princípios de IA que guiam nosso trabalho. Estes são padrões concretos que governam nossa pesquisa, desenvolvimento de produtos e decisões comerciais:

1. **A IA deve ser socialmente benéfica**  
    Qualquer projeto deve considerar fatores sociais e econômicos. Só avançamos quando acreditamos que os benefícios superam substancialmente os riscos.
    
2. **A IA deve evitar viés injusto**  
    Buscamos evitar impactos negativos em grupos vulneráveis, especialmente em relação a características sensíveis como raça, etnia, gênero, nacionalidade, renda, orientação sexual, habilidades e crenças políticas ou religiosas.
    
3. **A IA deve ser segura**  
    Desenvolvemos e aplicamos práticas rigorosas de segurança para evitar riscos inesperados.
    
4. **A IA deve ser responsável perante as pessoas**  
    Criamos sistemas que permitem feedback, explicações e a possibilidade de contestação.
    
5. **A IA deve incorporar princípios de privacidade**  
    Projetamos sistemas que priorizam transparência e controle sobre o uso de dados.
    
6. **A IA deve manter altos padrões de excelência científica**  
    Trabalhamos com especialistas para garantir que nossa IA seja desenvolvida com rigor científico e compartilhamos conhecimento de forma responsável.
    
7. **A IA deve ser utilizada de maneira alinhada com esses princípios**  
    Como muitas tecnologias possuem múltiplas aplicações, trabalhamos para evitar usos potencialmente prejudiciais ou abusivos.
    

Além desses princípios, há **quatro tipos de aplicações de IA que não desenvolvemos**:

1. Tecnologias que causam ou podem causar danos;
2. Armas ou tecnologias cujo principal propósito seja ferir pessoas;
3. Tecnologias que violem normas internacionais de privacidade e vigilância;
4. Tecnologias que contrariem leis internacionais e direitos humanos.

Os princípios de IA do Google não oferecem respostas diretas sobre como construir nossos produtos, nem devem ser usados para evitar discussões difíceis. Eles são a base do que defendemos, do que construímos e do motivo pelo qual fazemos isso. No centro de tudo, acreditamos que **IA responsável é sinônimo de IA bem-sucedida**.

Construímos nossos produtos com rigor e consistência, conduzindo avaliações para garantir que qualquer projeto esteja alinhado com nossos princípios de IA. Essas revisões garantem transparência e confiabilidade, para que mesmo quem não concorde com uma decisão final confie no processo que a gerou.

Obrigado por assistir! Para aprender mais sobre IA, confira nossos outros vídeos.


