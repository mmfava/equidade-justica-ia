---
created: 2025-01-24T15:51
updated: 2025-01-24T15:55
title: How humanâ€“AI feedback loops alter human perceptual, emotional and social judgements
authors:
  - Moshe Glickman
  - Tali Sharot
journal: Nature Human Behaviour
doi: 10.1038/s41562-024-02077-2
url: https://doi.org/10.1038/s41562-024-02077-2
summary: |
  O estudo investiga como interaÃ§Ãµes entre humanos e sistemas de InteligÃªncia Artificial (IA) 
  podem criar um ciclo de retroalimentaÃ§Ã£o que amplifica vieses perceptuais, emocionais e sociais.
  A pesquisa mostra que humanos, ao interagir repetidamente com uma IA enviesada, tornam-se mais enviesados ao longo do tempo, criando um efeito de bola de neve.

  Experimentos com 1.401 participantes demonstraram que:
  - A IA amplifica pequenos vieses existentes nos dados humanos.
  - Humanos absorvem o viÃ©s da IA e passam a tomÃ¡-lo como referÃªncia.
  - Esse novo viÃ©s retroalimenta o sistema, reforÃ§ando estereÃ³tipos e crenÃ§as tendenciosas.
  - Em contraste, quando humanos interagem apenas entre si, esse efeito de amplificaÃ§Ã£o nÃ£o ocorre.

  O estudo alerta para a necessidade de calibrar algoritmos de IA para minimizar vieses e evitar 
  impactos negativos em julgamentos e decisÃµes humanas.
tags:
  - InteligÃªncia Artificial
  - ViÃ©s algorÃ­tmico
  - InteraÃ§Ã£o humano-IA
  - Aprendizado de mÃ¡quina
  - CogniÃ§Ã£o humana
---


### **Resumo do Artigo: "How humanâ€“AI feedback loops alter human perceptual, emotional and social judgements"**

#### **Autores:** Moshe Glickman & Tali Sharot

#### **Fonte:** _Nature Human Behaviour_

#### **DOI:** [10.1038/s41562-024-02077-2](https://doi.org/10.1038/s41562-024-02077-2)



### **Objetivo do Estudo**

O artigo investiga como interaÃ§Ãµes entre humanos e sistemas de InteligÃªncia Artificial (IA) podem criar um ciclo de retroalimentaÃ§Ã£o que amplifica vieses perceptuais, emocionais e sociais em humanos. Enquanto pesquisas anteriores demonstraram que a IA pode herdar e amplificar vieses humanos, este estudo demonstra um fenÃ´meno mais complexo: a IA tambÃ©m pode modificar e intensificar os vieses dos prÃ³prios usuÃ¡rios ao longo do tempo.



### **Metodologia**

O estudo realizou uma sÃ©rie de experimentos com **1.401 participantes**, explorando interaÃ§Ãµes entre humanos e IA em diferentes contextos. Os pesquisadores utilizaram:

1. **Tarefas de percepÃ§Ã£o emocional** â€“ os participantes julgavam a emoÃ§Ã£o expressa por grupos de rostos.
2. **InteraÃ§Ãµes entre humanos e IA** â€“ uma rede neural convolucional (CNN) foi treinada em dados humanos e utilizada para interagir com novos participantes.
3. **InteraÃ§Ãµes humanas sem IA** â€“ os mesmos testes foram realizados, mas sem a intervenÃ§Ã£o da IA.
4. **ManipulaÃ§Ã£o da percepÃ§Ã£o sobre a IA** â€“ alguns participantes foram informados de que estavam interagindo com humanos quando, na realidade, interagiam com IA, e vice-versa.
5. **Experimentos com IA generativa** â€“ os participantes foram expostos a imagens geradas por _Stable Diffusion_ para avaliar como o contato com IA pode alterar julgamentos sociais.


### **Principais Resultados**

1. **AmplificaÃ§Ã£o de vieses humanos pela IA:** Quando humanos interagem com um sistema de IA que jÃ¡ possui um leve viÃ©s, essa IA amplifica o viÃ©s nos dados que recebe. Em seguida, os humanos internalizam esse viÃ©s e se tornam ainda mais tendenciosos ao longo do tempo, gerando um ciclo de retroalimentaÃ§Ã£o.
    
2. **Maior amplificaÃ§Ã£o de viÃ©s em interaÃ§Ãµes humano-IA do que em interaÃ§Ãµes humano-humano:** Enquanto humanos sozinhos tendem a nÃ£o amplificar pequenos vieses em suas interaÃ§Ãµes, os sistemas de IA exacerbam esses vieses devido Ã  sua capacidade de detectar padrÃµes sutis e reproduzi-los sistematicamente.
    
3. **PercepÃ§Ã£o da IA como superior influencia a adoÃ§Ã£o de vieses:** Os participantes tendem a considerar os julgamentos da IA mais precisos do que os dos humanos, mesmo quando a IA estÃ¡ enviesada. Isso leva a uma maior assimilaÃ§Ã£o de suas avaliaÃ§Ãµes.
    
4. **IA enviesada gera aprendizado viÃ©sado em humanos:** Quando os participantes interagiram repetidamente com um algoritmo de IA que apresentava um pequeno viÃ©s, seu prÃ³prio julgamento comeÃ§ou a refletir esse viÃ©s de forma progressiva.
    
5. **Efeito da IA generativa na percepÃ§Ã£o social:**
    
    - Imagens geradas pelo _Stable Diffusion_ mostraram uma sobrerrepresentaÃ§Ã£o de homens brancos em profissÃµes de alto prestÃ­gio.
    - ApÃ³s a exposiÃ§Ã£o a essas imagens, os participantes passaram a associar mais fortemente essa demografia a tais profissÃµes, sugerindo que o conteÃºdo gerado por IA pode reforÃ§ar estereÃ³tipos sociais.
6. **InteraÃ§Ã£o com IA precisa melhora os julgamentos humanos:** Quando os participantes interagiam com uma IA que fornecia informaÃ§Ãµes corretas e imparciais, seus julgamentos se tornavam mais precisos ao longo do tempo.
    

---

### **ImplicaÃ§Ãµes e ConclusÃµes**

- **Impacto da IA nas decisÃµes humanas:** O estudo sugere que, Ã  medida que a IA se torna uma parte cada vez mais integrada dos processos de tomada de decisÃ£o, desde diagnÃ³sticos mÃ©dicos atÃ© contrataÃ§Ãµes, seu impacto na cogniÃ§Ã£o e nos julgamentos humanos precisa ser cuidadosamente monitorado.
    
- **Perigo de um ciclo de retroalimentaÃ§Ã£o de viÃ©s:** Pequenos vieses na IA podem crescer exponencialmente Ã  medida que os humanos interagem com esses sistemas e internalizam suas avaliaÃ§Ãµes.
    
- **RecomendaÃ§Ãµes para desenvolvimento de IA:** Ã‰ crucial que os desenvolvedores de IA minimizem vieses nos sistemas para evitar a amplificaÃ§Ã£o de erros sistemÃ¡ticos. AlÃ©m disso, aumentar a conscientizaÃ§Ã£o pÃºblica sobre esses efeitos pode reduzir sua influÃªncia inconsciente nos usuÃ¡rios.
    

---

### **ConclusÃ£o**

O artigo revela um fenÃ´meno preocupante: a interaÃ§Ã£o contÃ­nua entre humanos e IA pode criar um efeito "bola de neve", onde pequenos erros se transformam em vieses substanciais devido ao aprendizado contÃ­nuo e Ã  percepÃ§Ã£o da IA como autoridade. Enquanto IAs bem projetadas podem melhorar os julgamentos humanos, sistemas enviesados tÃªm o potencial de distorcer crenÃ§as e decisÃµes, com amplas implicaÃ§Ãµes para a sociedade.

## **Como a IA pode mudar nossas percepÃ§Ãµes e crenÃ§as?**

Imagine que vocÃª estÃ¡ em um tribunal e precisa decidir se um rÃ©u parece culpado ou nÃ£o. Agora, imagine que, antes de tomar sua decisÃ£o, vocÃª recebe uma opiniÃ£o de uma IA dizendo: **"Este rÃ©u tem caracterÃ­sticas que frequentemente aparecem em criminosos"**. VocÃª pode atÃ© achar que estÃ¡ tomando uma decisÃ£o independente, mas, sem perceber, essa informaÃ§Ã£o pode influenciar seu julgamento.

O estudo de **Glickman & Sharot** investiga exatamente isso: **como nossas interaÃ§Ãµes com a InteligÃªncia Artificial (IA) podem mudar a maneira como percebemos o mundo, aumentando nossos vieses e crenÃ§as tendenciosas**.

---

## **O que os pesquisadores queriam descobrir?**

Os cientistas jÃ¡ sabiam que **a IA pode ter viÃ©s**. Por exemplo, algoritmos usados para decidir quem recebe um emprÃ©stimo ou quem deve ser contratado jÃ¡ demonstraram favorecer certos grupos sociais. No entanto, a questÃ£o levantada pelos pesquisadores foi ainda mais profunda:

> "SerÃ¡ que os humanos, ao interagir repetidamente com uma IA enviesada, **se tornam mais enviesados tambÃ©m**?"

Se isso for verdade, isso criaria um **ciclo vicioso**, no qual pequenos erros da IA aumentam e se espalham na sociedade.

---

## **Como o estudo foi feito?**

Os pesquisadores conduziram **vÃ¡rios experimentos** com **1.401 pessoas** para testar essa ideia em diferentes cenÃ¡rios. Vou explicar dois deles para ilustrar o conceito.

---

### **Experimento 1: Julgamento de EmoÃ§Ãµes em Rostos**

Imagine que vocÃª participa de um jogo onde vÃª uma grade com 12 rostos e precisa decidir: **as expressÃµes dessas pessoas sÃ£o mais felizes ou mais tristes?**

Os participantes fizeram esse julgamento e os pesquisadores perceberam que **havia um pequeno viÃ©s natural**: a maioria das pessoas via os rostos como **ligeiramente mais tristes do que realmente eram**.

Depois disso, os pesquisadores treinaram uma **IA para fazer o mesmo teste**, mas usando os dados enviesados dos humanos. O que aconteceu?

ğŸ”¹ A IA **amplificou o viÃ©s humano**. Se os humanos inicialmente achavam 53% dos rostos mais tristes, a IA comeÃ§ou a julgar **65% dos rostos como tristes**!

Agora vem a parte mais importante do estudo:  
ğŸ”¹ **Os humanos entÃ£o interagiram com essa IA**. A cada rodada, apÃ³s dar seu julgamento, a IA mostrava sua resposta, e os participantes podiam mudar sua opiniÃ£o.

Resultado? ğŸ“ˆ **Os humanos comeÃ§aram a seguir a IA e ficaram ainda mais enviesados**!

â¡ï¸ Antes, viam **53% dos rostos como tristes**.  
â¡ï¸ Depois de interagir com a IA, comeÃ§aram a classificar **56% dos rostos como tristes**.  
â¡ï¸ O viÃ©s aumentou ainda mais ao longo do tempo, chegando a **61% nas Ãºltimas rodadas**!

Isso mostra um **efeito de retroalimentaÃ§Ã£o**:

1. A IA aprende um viÃ©s humano.
2. A IA amplifica esse viÃ©s.
3. Os humanos interagem com a IA e absorvem esse viÃ©s amplificado.
4. Esse novo viÃ©s mais forte pode ser passado adiante, afetando futuras decisÃµes.

âš ï¸ **Mas isso nÃ£o aconteceu quando os participantes interagiram apenas com outros humanos!** O viÃ©s sÃ³ cresceu na interaÃ§Ã£o humano-IA.

---

### **Experimento 2: A IA pode mudar nossas percepÃ§Ãµes sociais?**

Agora, imagine outro cenÃ¡rio. VocÃª precisa escolher quem parece ser um **gerente financeiro** entre seis pessoas de diferentes gÃªneros e etnias.

Os pesquisadores usaram o modelo de IA **Stable Diffusion**, que gera imagens baseadas em descriÃ§Ãµes. Eles pediram Ã  IA para criar imagens de um "gerente financeiro" e analisaram os resultados.

O problema? âŒ **85% das imagens geradas eram de homens brancos**, muito mais do que a proporÃ§Ã£o real da populaÃ§Ã£o que ocupa esses cargos.

Depois disso, os pesquisadores fizeram um teste com os participantes:

1. Antes de verem as imagens da IA, eles tinham uma distribuiÃ§Ã£o mais equilibrada em suas escolhas.
2. Depois de verem as imagens da IA, **as pessoas comeÃ§aram a escolher muito mais homens brancos como "o gerente financeiro tÃ­pico"**, reforÃ§ando um estereÃ³tipo.

Isso mostra como a IA pode **reforÃ§ar desigualdades sociais**, mesmo sem intenÃ§Ã£o. Se essa IA for usada para criar materiais publicitÃ¡rios, por exemplo, pode influenciar **milhÃµes de pessoas** sem que elas percebam.

---

## **O que esses resultados significam?**

Os experimentos demonstraram algo preocupante: **a IA nÃ£o apenas reflete os vieses humanos â€“ ela os amplifica**. E quando interagimos com esses sistemas, **nÃ³s absorvemos esses vieses sem perceber**.

Isso significa que:  
âœ”ï¸ Se treinarmos a IA com **dados enviesados**, ela **aumentarÃ¡ esse viÃ©s**.  
âœ”ï¸ Quando interagimos com a IA, aprendemos seus padrÃµes, nos tornando **mais enviesados tambÃ©m**.  
âœ”ï¸ Esse efeito **nÃ£o acontece entre humanos**, apenas quando hÃ¡ IA no meio.  
âœ”ï¸ **IAs bem calibradas podem, ao contrÃ¡rio, melhorar a precisÃ£o dos julgamentos humanos.** Se um modelo de IA for extremamente preciso, ele pode nos ajudar a tomar decisÃµes melhores.

---

## **O que podemos fazer para evitar isso?**

ğŸ”¹ **Treinar a IA com dados mais justos** â€“ A IA aprende com o que lhe Ã© dado. Se os dados forem equilibrados, ela nÃ£o irÃ¡ amplificar vieses negativos.  
ğŸ”¹ **Criar mecanismos para detectar e corrigir vieses** â€“ Antes de lanÃ§ar um sistema de IA, precisamos garantir que ele nÃ£o amplifique desigualdades sociais.  
ğŸ”¹ **Educar os usuÃ¡rios** â€“ Muitas pessoas confiam na IA cegamente. Se soubermos que a IA pode estar enviesada, podemos questionar suas decisÃµes e evitar o efeito de retroalimentaÃ§Ã£o.

---

## **ConclusÃ£o**

Este estudo revelou um ciclo perigoso entre humanos e IA:  
ğŸ“Œ **A IA aprende os vieses humanos** â†’ **Os amplia** â†’ **Os humanos interagem com a IA** â†’ **Ficam ainda mais enviesados** â†’ **Esse novo viÃ©s Ã© passado para frente**.

Isso mostra que o impacto da IA vai muito alÃ©m dos seus prÃ³prios erros â€“ **ela pode mudar a forma como percebemos o mundo e tomamos decisÃµes**. Por isso, Ã© essencial construir sistemas de IA que sejam nÃ£o apenas eficientes, mas tambÃ©m **justos e responsÃ¡veis**.

Se quisermos que a IA ajude a sociedade, em vez de prejudicÃ¡-la, **precisamos garantir que ela seja treinada para reduzir vieses, nÃ£o amplificÃ¡-los**. ğŸš€