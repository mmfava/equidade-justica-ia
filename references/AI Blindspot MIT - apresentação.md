---
url: https://docs.google.com/presentation/d/1WVbdVZylXqYx1MnD12-CkzNWYJ7pzpwsTuESUbiSdUA/edit#slide=id.ga59d2cb710_0_0
title: AI Blindspot
author: MIT
alias: AI-blindspots-mit
created: 2025-01-22
updated: 2025-01-22T19:12
group: presentation
---

# AI Blindspot: Ferramentas para promover equidade em sistemas de IA

**Pense em um sistema de intelig√™ncia artificial que impacta sua comunidade atualmente.**  

Qual √© o seu prop√≥sito?  
Anote suas respostas em um papel ou processador de texto.

Se esse sistema fosse uma crian√ßa, o que voc√™ mais gostaria de ensinar a ela?  
Cole suas respostas no chat (1-2 palavras-chave).

---

## **Que tipo de IA estamos criando?**

### **Vis√£o Geral do Conceito**

**Conhe√ßa AL.**  
AL √© um ser infantil com um corpo humano e uma engrenagem no lugar da cabe√ßa. Assim como as crian√ßas refletem o ambiente e as pessoas ao seu redor, AL reflete os valores, prioridades e preconceitos das pessoas e dos sistemas que o criaram.

Podemos criar AL para ser **justo e √∫til**.  
Mas, se n√£o o fizermos, **AL pode prejudicar qualquer pessoa que tocar**.

---

## **Pontos cegos da IA (AI Blindspot)**

**Como o dano pode acontecer?**  
Traduzimos conceitos-chave sobre essa quest√£o em uma s√©rie de cen√°rios ilustrados, ou "pontos cegos". Eles mostram como cada um pode se manifestar se AL fosse uma pessoa.

1. **Dados Representativos**
2. **Discrimina√ß√£o por Proxy**
3. **Crit√©rios de Sucesso**
4. **Abusabilidade**
5. **Supervis√£o**
6. **Consulta P√∫blica**
7. **Privacidade**
8. **Prop√≥sito**
9. **Explicabilidade**
10. **Direito √† Contesta√ß√£o**
11. **Vi√©s Emergente**

---

### **Prop√≥sito**

O sistema de IA em quest√£o melhora o mundo?  
Ele tem um objetivo claramente definido que promove a confian√ßa entre indiv√≠duos e o p√∫blico?

---

### **Dados Representativos**

Os dados de treinamento s√£o representativos das comunidades que podem ser impactadas?  
Quem se beneficia com a forma como os dados s√£o coletados e organizados, e quem √© exclu√≠do ou prejudicado?

---

### **Abusabilidade**

Como agentes mal-intencionados podem sequestrar e usar o sistema para atividades prejudiciais?  
Os designers anteciparam vulnerabilidades?

---

### **Privacidade**

Os sistemas de IA frequentemente coletam informa√ß√µes pessoais que podem invadir nossa privacidade.  
Al√©m disso, sistemas que armazenam dados confidenciais podem estar vulner√°veis a ataques cibern√©ticos, resultando em **vazamentos de dados devastadores**.

---

### **Discrimina√ß√£o por Proxy**

Um algoritmo pode afetar negativamente popula√ß√µes vulner√°veis, mesmo sem incluir diretamente caracter√≠sticas protegidas (como ra√ßa ou g√™nero).  
Isso ocorre quando o modelo inclui vari√°veis que est√£o correlacionadas com essas caracter√≠sticas.

---

### **Explicabilidade**

Os algoritmos s√£o complexos, tornando dif√≠cil compreender suas recomenda√ß√µes.  
Quem projeta e implementa sistemas algor√≠tmicos tem a **responsabilidade de explicar** decis√µes de alto impacto que afetam o bem-estar das pessoas.

---

### **Crit√©rios de Sucesso**

Os indicadores de sucesso de um sistema de IA podem gerar impactos negativos.  
√â essencial equilibrar m√©tricas de desempenho com o risco de prejudicar **popula√ß√µes vulner√°veis**.

---

### **Vi√©s Emergente**

Entre o desenvolvimento e a implementa√ß√£o de um sistema de IA, **o mundo pode mudar**, fazendo com que os dados de treinamento deixem de ser representativos.

---

### **Direito √† Contesta√ß√£o**

Como qualquer processo humano, os sistemas de IA **s√£o subjetivos e imperfeitos**.  
O direito de contestar uma decis√£o algor√≠tmica pode revelar erros e garantir autonomia √†s pessoas afetadas.

---

### **Supervis√£o**

Princ√≠pios √©ticos, normas e pol√≠ticas s√£o **ineficazes se n√£o forem monitorados e aplicados**.  
Um **√≥rg√£o de supervis√£o diverso e com autoridade formal** pode ajudar a estabelecer transpar√™ncia, responsabiliza√ß√£o e san√ß√µes.

---

### **Consulta P√∫blica**

A participa√ß√£o p√∫blica deve estar presente em **todas as etapas do processo**.  
Praticantes de IA devem permitir **entrada significativa, explica√ß√µes e divulga√ß√µes**, garantindo que os sistemas promovam o bem-estar humano e reduzam danos.

---

## **Contexto**

Nenhum sistema de IA √© criado ou existe em um **v√°cuo**.  
(Exemplo: Como a vacina√ß√£o contra COVID-19 pode ser vista sob a √≥tica de uma IA equitativa versus a realidade).

---

## **Atividades do Workshop**

(Handouts ‚Äì Material de apoio)

**Voc√™ conhece AL?**

1. **AL √© um sistema de IA chamado...**
2. **AL est√° sendo "criado" por (pais, cuidadores, professores)...**
3. **AL est√° nos prejudicando em (comunidades, onde, como)...**
    - Moradores negros e latinos de Detroit
    - Perfis raciais
    - Vi√©s racial
    - Viol√™ncia policial
    - Pris√µes falsas (falsos positivos)
4. **AL est√° refor√ßando (sistemas, valores, pr√°ticas)...**
    - Reconhecimento facial
    - Racismo
    - Supremacia branca
    - Viola√ß√£o de direitos civis
5. **Mas podemos mudar essa hist√≥ria. Como podemos reagir?**
    - Aprender mais sobre esse sistema
    - Educar e organizar nossas comunidades
    - Exigir transpar√™ncia e responsabiliza√ß√£o do governo municipal
    - Reverter completamente o uso dessa tecnologia

---

## **Sobre o projeto AI Blindspot**

**Origem do Projeto**  
O **AI Blindspot** √© uma iniciativa de **Ania Calderon, Dan Taber, Hong Qu e Jeff Wen**, desenvolvida no **Berkman Klein Center** e no **MIT Media Lab‚Äôs 2019 Assembly Program**.

A equipe criou um **baralho de 10 cartas** que ajuda usu√°rios a identificar vieses e desigualdades estruturais em sistemas de IA.  
Originalmente projetadas para equipes t√©cnicas, percebeu-se que seu impacto seria maior se **grupos da sociedade civil** tamb√©m as utilizassem para promover justi√ßa na IA.

üìç [Site do projeto](https://aiblindspot.media.mit.edu/)

---

## **Nossa vis√£o**

Imaginamos um mundo em que a intelig√™ncia artificial seja **usada de forma respons√°vel e equitativa** para resolver problemas complexos.  
A IA deve ser usada **apenas quando for a ferramenta apropriada** para a tarefa.

Acreditamos que a cria√ß√£o de sistemas de IA deve:  
‚úî Priorizar as necessidades e preocupa√ß√µes daqueles que correm maior risco de serem prejudicados  
‚úî Distribuir os benef√≠cios da IA de maneira equitativa  
‚úî Ser regulada por pol√≠ticas e supervis√£o **respons√°veis e transparentes**

---

## **Nossa miss√£o**

Fornecendo **uma linguagem comum** sobre IA, o AI Blindspot busca reduzir barreiras entre aqueles que desenvolvem sistemas de IA e aqueles que n√£o os criam ‚Äì especialmente **atores da sociedade civil que trabalham por sistemas mais justos**.

Ao **desmistificar** como os sistemas de IA podem ser prejudiciais para comunidades vulner√°veis, o AI Blindspot **ajuda ativistas a responsabilizar desenvolvedores, fornecedores e formuladores de pol√≠ticas**.

---

## **Parcerias**

O AI Blindspot firmou uma parceria com **The Consentful Tech Project**, iniciativa do est√∫dio de design **And Also Too**.  
Realizaram pesquisas com organiza√ß√µes como **Detroit Community Technology Project e Access Now**, ambas defensoras da equidade e justi√ßa na IA.

Essa pesquisa ajudou a desenvolver uma **abordagem art√≠stica e narrativa** para os pontos cegos da IA, apresentada neste workshop.

üåê [Detroit Community Tech](http://detroitcommunitytech.org/)  
üåê [Access Now](https://www.accessnow.org/)  
üåê [Consentful Tech](https://www.consentfultech.io/)  
üåê [And Also Too](http://andalsotoo.net/)

---

Essa foi a tradu√ß√£o do conte√∫do dos slides. Se precisar de ajustes ou mais detalhes, me avise! üòä